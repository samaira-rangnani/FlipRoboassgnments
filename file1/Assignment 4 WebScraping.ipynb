{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1555b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementNotInteractableException as e\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b0ef6",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4683996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a4e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting uRL\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "520c1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()     ##maximizing the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b46468aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the rank\n",
    "rank=[]\n",
    "rt=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "for i in rt:\n",
    "    rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50681564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', '13.', '14.', '15.', '16.', '17.', '18.', '19.', '20.', '21.', '22.', '23.', '24.', '25.', '26.', '27.', '28.', '29.', '30.']\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c639c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting name \n",
    "name=[]\n",
    "nt=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "for i in nt:\n",
    "    name.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c7634e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['\"Baby Shark Dance\"[6]', '\"Despacito\"[9]', '\"Johny Johny Yes Papa\"[17]', '\"Bath Song\"[18]', '\"Shape of You\"[19]', '\"See You Again\"[22]', '\"Wheels on the Bus\"[27]', '\"Phonics Song with Two Words\"[28]', '\"Uptown Funk\"[29]', '\"Learning Colors – Colorful Eggs on a Farm\"[30]', '\"Gangnam Style\"[31]', '\"Masha and the Bear – Recipe for Disaster\"[36]', '\"Dame Tu Cosita\"[37]', '\"Axel F\"[38]', '\"Sugar\"[39]', '\"Counting Stars\"[40]', '\"Roar\"[41]', '\"Baa Baa Black Sheep\"[42]', '\"Waka Waka (This Time for Africa)\"[43]', '\"Lakdi Ki Kathi\"[44]', '\"Sorry\"[45]', '\"Thinking Out Loud\"[46]', '\"Humpty the train on a fruits ride\"[47]', '\"Dark Horse\"[48]', '\"Perfect\"[49]', '\"Let Her Go\"[50]', '\"Faded\"[51]', '\"Shree Hanuman Chalisa\"[52]', '\"Girls Like You\"[53]', '\"Lean On\"[54]']\n"
     ]
    }
   ],
   "source": [
    "print(len(name),name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f55b9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting artist\n",
    "artist=[]\n",
    "at=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "for i in at:\n",
    "    artist.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab66c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 [\"Pinkfong Baby Shark - Kids' Songs & Stories\", 'Luis Fonsi', \"LooLoo Kids - Nursery Rhymes and Children's Songs\", 'Cocomelon - Nursery Rhymes', 'Ed Sheeran', 'Wiz Khalifa', 'Cocomelon - Nursery Rhymes', 'ChuChu TV Nursery Rhymes & Kids Songs', 'Mark Ronson', 'Miroshka TV', 'officialpsy', 'Get Movies', 'Ultra Records', 'Crazy Frog', 'Maroon 5', 'OneRepublic', 'Katy Perry', 'Cocomelon - Nursery Rhymes', 'Shakira', 'Jingle Toons', 'Justin Bieber', 'Ed Sheeran', 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs', 'Katy Perry', 'Ed Sheeran', 'Passenger', 'Alan Walker', 'T-Series Bhakti Sagar', 'Maroon 5', 'Major Lazer Official']\n"
     ]
    }
   ],
   "source": [
    "print(len(artist),artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60f7784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting views\n",
    "views=[]\n",
    "vt=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "for i in vt:\n",
    "    views.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511c19e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['13.65', '8.32', '6.84', '6.50', '6.14', '6.09', '5.71', '5.57', '5.09', '5.01', '4.96', '4.57', '4.48', '4.16', '3.97', '3.92', '3.91', '3.84', '3.78', '3.76', '3.74', '3.69', '3.63', '3.63', '3.60', '3.56', '3.55', '3.54', '3.52', '3.50']\n"
     ]
    }
   ],
   "source": [
    "print(len(views),views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff931994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting upload date\n",
    "upload_date=[]\n",
    "udt=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "for i in udt:\n",
    "    upload_date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "708b9d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['June 17, 2016', 'January 12, 2017', 'October 8, 2016', 'May 2, 2018', 'January 30, 2017', 'April 6, 2015', 'May 24, 2018', 'March 6, 2014', 'November 19, 2014', 'February 27, 2018', 'July 15, 2012', 'January 31, 2012', 'April 5, 2018', 'June 16, 2009', 'January 14, 2015', 'May 31, 2013', 'September 5, 2013', 'June 25, 2018', 'June 4, 2010', 'June 14, 2018', 'October 22, 2015', 'October 7, 2014', 'January 26, 2018', 'February 20, 2014', 'November 9, 2017', 'July 25, 2012', 'December 3, 2015', 'May 10, 2011', 'May 31, 2018', 'March 22, 2015']\n"
     ]
    }
   ],
   "source": [
    "print(len(upload_date),upload_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c13017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.65</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.32</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.84</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.50</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.14</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.09</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.71</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.57</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.09</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.01</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.96</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.57</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.48</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.16</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.97</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.92</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.91</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.84</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.78</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.76</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.74</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.69</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.63</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.63</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.60</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.56</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.55</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[52]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.54</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.52</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.50</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                             \"Lakdi Ki Kathi\"[44]   \n",
       "20  21.                                      \"Sorry\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.          \"Humpty the train on a fruits ride\"[47]   \n",
       "23  24.                                 \"Dark Horse\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                      \"Shree Hanuman Chalisa\"[52]   \n",
       "28  29.                             \"Girls Like You\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist  Views  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories  13.65   \n",
       "1                                          Luis Fonsi   8.32   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.84   \n",
       "3                          Cocomelon - Nursery Rhymes   6.50   \n",
       "4                                          Ed Sheeran   6.14   \n",
       "5                                         Wiz Khalifa   6.09   \n",
       "6                          Cocomelon - Nursery Rhymes   5.71   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   5.57   \n",
       "8                                         Mark Ronson   5.09   \n",
       "9                                         Miroshka TV   5.01   \n",
       "10                                        officialpsy   4.96   \n",
       "11                                         Get Movies   4.57   \n",
       "12                                      Ultra Records   4.48   \n",
       "13                                         Crazy Frog   4.16   \n",
       "14                                           Maroon 5   3.97   \n",
       "15                                        OneRepublic   3.92   \n",
       "16                                         Katy Perry   3.91   \n",
       "17                         Cocomelon - Nursery Rhymes   3.84   \n",
       "18                                            Shakira   3.78   \n",
       "19                                       Jingle Toons   3.76   \n",
       "20                                      Justin Bieber   3.74   \n",
       "21                                         Ed Sheeran   3.69   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.63   \n",
       "23                                         Katy Perry   3.63   \n",
       "24                                         Ed Sheeran   3.60   \n",
       "25                                          Passenger   3.56   \n",
       "26                                        Alan Walker   3.55   \n",
       "27                              T-Series Bhakti Sagar   3.54   \n",
       "28                                           Maroon 5   3.52   \n",
       "29                               Major Lazer Official   3.50   \n",
       "\n",
       "          Upload_date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19      June 14, 2018  \n",
       "20   October 22, 2015  \n",
       "21    October 7, 2014  \n",
       "22   January 26, 2018  \n",
       "23  February 20, 2014  \n",
       "24   November 9, 2017  \n",
       "25      July 25, 2012  \n",
       "26   December 3, 2015  \n",
       "27       May 10, 2011  \n",
       "28       May 31, 2018  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "df1=pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Views':views,'Upload_date':upload_date})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bef52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9af294",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/. \n",
    "You need to find following details: \n",
    "A) Series \n",
    "B) Place \n",
    "C) Date \n",
    "D) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e6d41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a08945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03d469ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()    ##Maximizing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d262920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on fixtures\n",
    "fixtures=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[1]/ul/div[1]/a[2]')\n",
    "fixtures.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "729f01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clicking on filter to India\n",
    "filter=driver.find_elements(By.XPATH,'//div[@class=\"cSBListItems ng-binding ng-scope\"]')\n",
    "for i in filter:\n",
    "    if i.text=='India':\n",
    "        i.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f68ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store desried data\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1881f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping series\n",
    "try:\n",
    "    st=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope t20-tag\"]')\n",
    "    for i in st:\n",
    "        series.append(i.text)\n",
    "        \n",
    "finally:\n",
    "    extratags=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope odi-tag\"]')\n",
    "    for i in extratags:\n",
    "        series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53e76cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 ['2nd T20I', '3rd T20I', '4th T20I', '5th T20I', '1st T20I', '2nd T20I', '3rd T20I', '1st ODI', '2nd ODI']\n"
     ]
    }
   ],
   "source": [
    "print(len(series),series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8fb5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 ['Greenfield International Stadium, Thiruvananthapuram', 'Barsapara Cricket Stadium, Guwahati', 'Shaheed Veer Narayan Singh International Cricket Stadium, Raipur', 'M Chinnaswamy Stadium, Bengaluru', 'Kingsmead, Durban', \"St George's Park, Gqeberha\", 'The Wanderers Stadium, Johannesburg', 'Johannesburg', \"St George's Park, Gqeberha\"]\n"
     ]
    }
   ],
   "source": [
    "#scrapping place\n",
    "placetag=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "for i in placetag:\n",
    "    place.append(i.text)\n",
    "    \n",
    "print(len(place),place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfd93e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping date\n",
    "dtag=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in dtag:\n",
    "    date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09039e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 ['26 NOVEMBER, 2023', '28 NOVEMBER, 2023', '1 DECEMBER, 2023', '3 DECEMBER, 2023', '10 DECEMBER, 2023', '12 DECEMBER, 2023', '14 DECEMBER, 2023', '17 DECEMBER, 2023', '19 DECEMBER, 2023']\n"
     ]
    }
   ],
   "source": [
    "print(len(date),date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4efacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping time\n",
    "ttag=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "\n",
    "for i in ttag:\n",
    "    time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac2039c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 ['7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '9:30 PM IST', '9:30 PM IST', '9:30 PM IST', '2:00 PM IST', '2:00 PM IST']\n"
     ]
    }
   ],
   "source": [
    "print(len(time),time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff042c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Greenfield International Stadium, Thiruvananth...</td>\n",
       "      <td>26 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Barsapara Cricket Stadium, Guwahati</td>\n",
       "      <td>28 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>Shaheed Veer Narayan Singh International Crick...</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Kingsmead, Durban</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>12 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>The Wanderers Stadium, Johannesburg</td>\n",
       "      <td>14 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>17 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>19 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Series                                              Place  \\\n",
       "0  2nd T20I  Greenfield International Stadium, Thiruvananth...   \n",
       "1  3rd T20I                Barsapara Cricket Stadium, Guwahati   \n",
       "2  4th T20I  Shaheed Veer Narayan Singh International Crick...   \n",
       "3  5th T20I                   M Chinnaswamy Stadium, Bengaluru   \n",
       "4  1st T20I                                  Kingsmead, Durban   \n",
       "5  2nd T20I                         St George's Park, Gqeberha   \n",
       "6  3rd T20I                The Wanderers Stadium, Johannesburg   \n",
       "7   1st ODI                                       Johannesburg   \n",
       "8   2nd ODI                         St George's Park, Gqeberha   \n",
       "\n",
       "                Date         Time  \n",
       "0  26 NOVEMBER, 2023  7:00 PM IST  \n",
       "1  28 NOVEMBER, 2023  7:00 PM IST  \n",
       "2   1 DECEMBER, 2023  7:00 PM IST  \n",
       "3   3 DECEMBER, 2023  7:00 PM IST  \n",
       "4  10 DECEMBER, 2023  9:30 PM IST  \n",
       "5  12 DECEMBER, 2023  9:30 PM IST  \n",
       "6  14 DECEMBER, 2023  9:30 PM IST  \n",
       "7  17 DECEMBER, 2023  2:00 PM IST  \n",
       "8  19 DECEMBER, 2023  2:00 PM IST  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##making dataframe\n",
    "df2=pd.DataFrame({'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "079725ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce7a4a",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details: A) Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "38b0aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f31907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89d5a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()     ##maximizing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cfc07cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clicking on economy button\n",
    "economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economy.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5e13031",
   "metadata": {},
   "outputs": [],
   "source": [
    "India=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "India.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "109e2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on Indian state gdp\n",
    "gdp=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e934dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store desired data\n",
    "rank=[] \n",
    "state=[]\n",
    "gdp_18_19=[] \n",
    "gdp_19_20=[]\n",
    "share=[]\n",
    "gdp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7e76d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping rank\n",
    "ranktag=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "for i in ranktag:\n",
    "    rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc0be70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33']\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3b7ea012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping state\n",
    "stag=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "for i in stag:\n",
    "    state.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "de2e800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Gujarat', 'Karnataka', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands']\n"
     ]
    }
   ],
   "source": [
    "print(len(state),state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64957eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping gdp_18_19\n",
    "gtag=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "for i in gtag:\n",
    "    gdp_18_19.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79733e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['-', '1,845,853', '1,687,818', '-', '1,631,977', '1,253,832', '1,020,989', '972,782', '969,604', '906,672', '-', '856,112', '831,610', '611,804', '574,760', '521,275', '-', '329,180', '328,598', '-', '-', '165,472', '80,449', '55,984', '-', '38,253', '36,572', '32,496', '31,790', '-', '-', '26,503', '-']\n"
     ]
    }
   ],
   "source": [
    "print(len(gdp_18_19),gdp_18_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2ca7e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping gdp_19_20\n",
    "gdtag=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "for i in gdtag:\n",
    "    gdp_19_20.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d527cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,632,792', '1,630,208', '1,584,764', '1,502,899', '1,493,127', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '487,805', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '34,433', '33,481', '28,723', '27,870', '27,283', '24,603', '22,287', '-']\n"
     ]
    }
   ],
   "source": [
    "print(len(gdp_19_20),gdp_19_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cf153fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Share_18\n",
    "sharetag=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "for i in sharetag:\n",
    "    share.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7517bc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['13.94%', '8.63%', '8.39%', '7.96%', '7.91%', '5.77%', '4.99%', '4.57%', '4.56%', '4.29%', '4.14%', '4.10%', '3.89%', '2.81%', '2.79%', '2.58%', '1.67%', '1.61%', '1.57%', '1.30%', '0.83%', '0.81%', '0.39%', '0.26%', '0.22%', '0.18%', '0.18%', '0.15%', '0.15%', '0.14%', '0.13%', '0.12%', '-']\n"
     ]
    }
   ],
   "source": [
    "print(len(share),share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0911c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping gdp\n",
    "gdptag=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "for i in gdptag:\n",
    "    gdp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "faae83f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['399.921', '247.629', '240.726', '228.290', '226.806', '165.556', '143.179', '131.083', '130.791', '122.977', '118.733', '117.703', '111.519', '80.562', '79.957', '74.098', '47.982', '46.187', '45.145', '37.351', '23.690', '23.369', '11.115', '7.571', '6.397', '5.230', '5.086', '4.363', '4.233', '4.144', '3.737', '3.385', '-']\n"
     ]
    }
   ],
   "source": [
    "print(len(gdp),gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e951feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                      2,632,792   \n",
       "1     2                 Tamil Nadu                      1,630,208   \n",
       "2     3              Uttar Pradesh                      1,584,764   \n",
       "3     4                    Gujarat                      1,502,899   \n",
       "4     5                  Karnataka                      1,493,127   \n",
       "5     6                West Bengal                      1,089,898   \n",
       "6     7                  Rajasthan                        942,586   \n",
       "7     8             Andhra Pradesh                        862,957   \n",
       "8     9                  Telangana                        861,031   \n",
       "9    10             Madhya Pradesh                        809,592   \n",
       "10   11                     Kerala                        781,653   \n",
       "11   12                      Delhi                        774,870   \n",
       "12   13                    Haryana                        734,163   \n",
       "13   14                      Bihar                        530,363   \n",
       "14   15                     Punjab                        526,376   \n",
       "15   16                     Odisha                        487,805   \n",
       "16   17                      Assam                        315,881   \n",
       "17   18               Chhattisgarh                        304,063   \n",
       "18   19                  Jharkhand                        297,204   \n",
       "19   20                Uttarakhand                        245,895   \n",
       "20   21            Jammu & Kashmir                        155,956   \n",
       "21   22           Himachal Pradesh                        153,845   \n",
       "22   23                        Goa                         73,170   \n",
       "23   24                    Tripura                         49,845   \n",
       "24   25                 Chandigarh                         42,114   \n",
       "25   26                 Puducherry                         34,433   \n",
       "26   27                  Meghalaya                         33,481   \n",
       "27   28                     Sikkim                         28,723   \n",
       "28   29                    Manipur                         27,870   \n",
       "29   30                   Nagaland                         27,283   \n",
       "30   31          Arunachal Pradesh                         24,603   \n",
       "31   32                    Mizoram                         22,287   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at current prices Share(18-19) GDP($ billion)  \n",
       "0                               -       13.94%        399.921  \n",
       "1                       1,845,853        8.63%        247.629  \n",
       "2                       1,687,818        8.39%        240.726  \n",
       "3                               -        7.96%        228.290  \n",
       "4                       1,631,977        7.91%        226.806  \n",
       "5                       1,253,832        5.77%        165.556  \n",
       "6                       1,020,989        4.99%        143.179  \n",
       "7                         972,782        4.57%        131.083  \n",
       "8                         969,604        4.56%        130.791  \n",
       "9                         906,672        4.29%        122.977  \n",
       "10                              -        4.14%        118.733  \n",
       "11                        856,112        4.10%        117.703  \n",
       "12                        831,610        3.89%        111.519  \n",
       "13                        611,804        2.81%         80.562  \n",
       "14                        574,760        2.79%         79.957  \n",
       "15                        521,275        2.58%         74.098  \n",
       "16                              -        1.67%         47.982  \n",
       "17                        329,180        1.61%         46.187  \n",
       "18                        328,598        1.57%         45.145  \n",
       "19                              -        1.30%         37.351  \n",
       "20                              -        0.83%         23.690  \n",
       "21                        165,472        0.81%         23.369  \n",
       "22                         80,449        0.39%         11.115  \n",
       "23                         55,984        0.26%          7.571  \n",
       "24                              -        0.22%          6.397  \n",
       "25                         38,253        0.18%          5.230  \n",
       "26                         36,572        0.18%          5.086  \n",
       "27                         32,496        0.15%          4.363  \n",
       "28                         31,790        0.15%          4.233  \n",
       "29                              -        0.14%          4.144  \n",
       "30                              -        0.13%          3.737  \n",
       "31                         26,503        0.12%          3.385  \n",
       "32                              -            -              -  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "df3=pd.DataFrame({\"Rank\":rank, 'State': state ,'GSDP(18-19)- at current prices':gdp_19_20, 'GSDP(19-20)- at current prices':gdp_18_19, 'Share(18-19)':share,'GDP($ billion)':gdp})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "66a16b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16977d3",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/ \n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5755ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting drver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be981dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee2a1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()   ###maximizing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d15f024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clicking on opensources\n",
    "try:\n",
    "    os=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "    os.click()\n",
    "except e :\n",
    "    element=driver.find_element(By.XPATH,'//li[@class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\"][3]')\n",
    "    element.click()\n",
    "    time.sleep(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "adcfe14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on trending option\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c2c7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extarcting desrired data\n",
    "title=[]\n",
    "description=[]\n",
    "count=[]\n",
    "language=[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e736fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarpping url of each repository\n",
    "urltag=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in urltag:\n",
    "    url.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "460b5b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['https://github.com/LouisShark/chatgpt_system_prompt', 'https://github.com/run-llama/rags', 'https://github.com/linexjlin/GPTs', 'https://github.com/1Panel-dev/1Panel', 'https://github.com/GrowingGit/GitHub-Chinese-Top-Charts', 'https://github.com/atomicals/atomicals-js', 'https://github.com/opa334/TrollStore', 'https://github.com/jordan-cutler/path-to-senior-engineer-handbook', 'https://github.com/BurntSushi/ripgrep', 'https://github.com/bgstaal/multipleWindow3dScene', 'https://github.com/Ftindy/IPTV-URL', 'https://github.com/yairm210/Unciv', 'https://github.com/pointfreeco/swift-composable-architecture', 'https://github.com/microsoft/AI-For-Beginners', 'https://github.com/spring-projects/spring-boot', 'https://github.com/biomejs/biome', 'https://github.com/udlbook/udlbook', 'https://github.com/nlohmann/json', 'https://github.com/Ma-Lab-Berkeley/CRATE', 'https://github.com/ShinoKana/multipleWindow3dScene', 'https://github.com/goniszewski/grimoire', 'https://github.com/zennomi/Seg-Mirror', 'https://github.com/googleapis/google-api-php-client', 'https://github.com/grpc-ecosystem/grpc-gateway', 'https://github.com/kamranahmedse/developer-roadmap']\n"
     ]
    }
   ],
   "source": [
    "print(len(url),url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca25e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting title tag\n",
    "titletag=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in titletag:\n",
    "    title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc717b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['LouisShark / chatgpt_system_prompt', 'run-llama / rags', 'linexjlin / GPTs', '1Panel-dev / 1Panel', 'GrowingGit / GitHub-Chinese-Top-Charts', 'atomicals / atomicals-js', 'opa334 / TrollStore', 'jordan-cutler / path-to-senior-engineer-handbook', 'BurntSushi / ripgrep', 'bgstaal / multipleWindow3dScene', 'Ftindy / IPTV-URL', 'yairm210 / Unciv', 'pointfreeco / swift-composable-architecture', 'microsoft / AI-For-Beginners', 'spring-projects / spring-boot', 'biomejs / biome', 'udlbook / udlbook', 'nlohmann / json', 'Ma-Lab-Berkeley / CRATE', 'ShinoKana / multipleWindow3dScene', 'goniszewski / grimoire', 'zennomi / Seg-Mirror', 'googleapis / google-api-php-client', 'grpc-ecosystem / grpc-gateway', 'kamranahmedse / developer-roadmap']\n"
     ]
    }
   ],
   "source": [
    "print(len(title),title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4d1d49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting description\n",
    "dtag=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in dtag:\n",
    "    if i.text is None:\n",
    "        description.append('--')\n",
    "    else:\n",
    "            description.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2caf78d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 [\"store all agent's system prompt\", 'Build ChatGPT over your data, all with natural language', 'leaked prompts of GPTs', '🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。', '🇨🇳 GitHub中文排行榜，各语言分设「软件 | 资料」榜单，精准定位中文好项目。各取所需，高效学习。', 'Atomicals CLI and Javascript Library', 'Jailed iOS app that can install IPAs permanently with arbitary entitlements and root helpers because it trolls Apple', 'All the resources you need to get to Senior Engineer and beyond', 'ripgrep recursively searches directories for a regex pattern while respecting your gitignore', 'A quick example of how one can \"synchronize\" a 3d scene across multiple windows using three.js and localStorage', 'Open-source Android/Desktop remake of Civ V', 'A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.', '12 Weeks, 24 Lessons, AI for All!', 'Spring Boot', 'A toolchain for web projects, aimed to provide functionalities to maintain them. Biome offers formatter and linter, usable via CLI and LSP.', 'Understanding Deep Learning - Simon J.D. Prince', 'JSON for Modern C++', 'Code for CRATE (Coding RAte reduction TransformEr).', 'based on bgstaal/multipleWindow3dScene', 'Bookmark manager for the wizards 🧙', 'Kính chiếu yêuuuu quỷ seg hiện raaa', 'A PHP client library for accessing Google APIs', 'gRPC to JSON proxy generator following the gRPC HTTP spec', 'Interactive roadmaps, guides and other educational content to help developers grow in their careers.']\n"
     ]
    }
   ],
   "source": [
    "print(len(description),description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d264ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b8a9ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "description.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "70850509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException as nse\n",
    "#extracting language\n",
    "\n",
    "ltag=driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')\n",
    "for i in ltag:\n",
    "    if i.text==None:\n",
    "            language.append('--')\n",
    "    else:\n",
    "            language.append(i.text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e15d6351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ['C', 'Python', 'Go', 'Java', 'TypeScript', 'C', 'Rust', 'JavaScript', 'Kotlin', 'Swift', 'Jupyter Notebook', 'Java', 'Rust', 'Jupyter Notebook', 'C++', 'Python', 'JavaScript', 'Svelte', 'JavaScript', 'PHP', 'Go', 'TypeScript']\n"
     ]
    }
   ],
   "source": [
    "print(len(language),language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8722b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "language.extend(['-','-','-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "21c6e80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['C', 'Python', 'Go', 'Java', 'TypeScript', 'C', 'Rust', 'JavaScript', 'Kotlin', 'Swift', 'Jupyter Notebook', 'Java', 'Rust', 'Jupyter Notebook', 'C++', 'Python', 'JavaScript', 'Svelte', 'JavaScript', 'PHP', 'Go', 'TypeScript', '-', '-', '-']\n"
     ]
    }
   ],
   "source": [
    "print(len(language),language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aa3d8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException as nse\n",
    "#extracting contributors count\n",
    "\n",
    "for page in url:\n",
    "    driver.get(page)\n",
    "    try:\n",
    "        ctag=driver.find_element(By.XPATH,'//div[@class=\"BorderGrid-row\"][5]/div/h2/a/span')\n",
    "\n",
    "        count.append(ctag.text)\n",
    "    \n",
    "    except nse:\n",
    "        count.append('--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee74809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['4', '5', '3', '38', '--', '11', '22', '9', '--', '2', '2', '464', '--', '33', '1,039', '960', '5', '264', '5', '--', '3', '--', '153', '345', '--']\n"
     ]
    }
   ],
   "source": [
    "print(len(count),count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04ca2f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 25\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(description),len(count),len(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46c3231f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##making dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df4\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRepository title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRepository description\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContributors count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLanguage used\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df4\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "##making dataframe\n",
    "df4=pd.DataFrame({'Repository title':title , 'Repository description':description ,'Contributors count':count[:25] , 'Language used':language })\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b3c85",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c2da680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0618b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('http://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7d10e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()    ###maximizing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0130f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on charts option\n",
    "chart=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3')\n",
    "chart.click()\n",
    "time.sleep(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaacf7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on billboard\n",
    "bill=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "bill.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e048d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating empty list to store data\n",
    "song=[]\n",
    "artist=[]\n",
    "week_rank=[]\n",
    "peek_rank=[]\n",
    "weeks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17a4bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting song name\n",
    "songtag=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in songtag:\n",
    "    song.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8c87803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Cruel Summer', 'Lovin On Me', 'Paint The Town Red', 'Snooze', \"Is It Over Now? (Taylor's Version) [From The Vault]\", 'I Remember Everything', 'Fast Car', 'Greedy', 'Last Night', \"Thinkin' Bout Me\", 'Houdini', 'White Horse', 'Need A Favor', 'Agora Hills', 'Water', 'Rich Baby Daddy', 'All I Want For Christmas Is You', 'Fukumean', 'Save Me', 'Dance The Night', 'Vampire', 'Used To Be Young', 'Lil Boo Thang', 'Monaco', 'First Person Shooter', 'IDGAF', 'What Was I Made For?', 'Good Good', 'Flowers', 'My Love Mine All Mine', 'Stick Season', 'Last Christmas', \"Now That We Don't Talk (Taylor's Version) [From The Vault]\", 'Dial Drunk', 'What It Is (Block Boy)', 'Kill Bill', 'Northern Attitude', 'Jingle Bell Rock', 'Lose Control', 'Harley Quinn', 'Daylight', 'I Know ?', 'Wild Ones', 'A Holly Jolly Christmas', 'Barbie World', 'Pretty Little Poison', 'World On Fire', 'On My Mama', \"Slut! (Taylor's Version) [From The Vault]\", 'Standing Next To You', '500lbs', 'Strangers', \"Say Don't Go (Taylor's Version) [From The Vault]\", 'Bad Idea Right?', 'Great Gatsby', 'Get Him Back!', \"Can't Have Mine\", 'Virginia Beach', 'Everything I Love', 'Standing Room Only', 'Try That In A Small Town', 'The Painter', 'Cobra', 'Truck Bed', 'Qlona', 'Too Much', 'Perro Negro', 'Hey Driver', \"Style (Taylor's Version)\", 'Rich Men North Of Richmond', 'Meltdown', 'Bongos', 'Slime You Out', 'Segun Quien', 'Que Onda', 'Now And Then', 'Single Soon', 'Burn It Down', 'LaLa', \"Bad Blood (Taylor's Version)\", \"Can't Catch Me Now\", 'Turks & Caicos', 'SkeeYee', '3D', \"Out Of The Woods (Taylor's Version)\", \"Wildest Dreams (Taylor's Version)\", 'El Amor de Su Vida', 'Save Me The Trouble', 'Stars Like Confetti', 'LALALALA', 'Seven', \"Suburban Legends (Taylor's Version) [From The Vault]\", \"Blank Space (Taylor's Version)\", \"We Don't Fight Anymore\", 'Smurk Carter', 'Mi Ex Tenia Razon', \"Different 'Round Here\", 'But I Got A Beer In My Hand', 'Better Than Ever', 'Soak City (Do It)']\n"
     ]
    }
   ],
   "source": [
    "print(len(song),song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aeb57534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting artist name\n",
    "atag=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')\n",
    "for i in atag:\n",
    "    artist.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "789e236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Taylor Swift', 'Jack Harlow', 'Doja Cat', 'SZA', 'Taylor Swift', 'Zach Bryan Featuring Kacey Musgraves', 'Luke Combs', 'Tate McRae', 'Morgan Wallen', 'Morgan Wallen', 'Dua Lipa', 'Chris Stapleton', 'Jelly Roll', 'Doja Cat', 'Tyla', 'Drake Featuring Sexyy Red & SZA', 'Mariah Carey', 'Gunna', 'Jelly Roll With Lainey Wilson', 'Dua Lipa', 'Olivia Rodrigo', 'Miley Cyrus', 'Paul Russell', 'Bad Bunny', 'Drake Featuring J. Cole', 'Drake Featuring Yeat', 'Billie Eilish', 'Usher, Summer Walker & 21 Savage', 'Miley Cyrus', 'Mitski', 'Noah Kahan', 'Wham!', 'Taylor Swift', 'Noah Kahan With Post Malone', 'Doechii Featuring Kodak Black', 'SZA', 'Noah Kahan With Hozier', 'Bobby Helms', 'Teddy Swims', 'Fuerza Regida & Marshmello', 'David Kushner', 'Travis Scott', 'Jessie Murph & Jelly Roll', 'Burl Ives', 'Nicki Minaj & Ice Spice With Aqua', 'Warren Zeiders', 'Nate Smith', 'Victoria Monet', 'Taylor Swift', 'Jung Kook', 'Lil Tecca', 'Kenya Grace', 'Taylor Swift', 'Olivia Rodrigo', 'Rod Wave', 'Olivia Rodrigo', 'Dylan Scott', 'Drake', 'Morgan Wallen', 'Tim McGraw', 'Jason Aldean', 'Cody Johnson', 'Megan Thee Stallion', 'HARDY', 'Karol G & Peso Pluma', 'The Kid LAROI, Jung Kook & Central Cee', 'Bad Bunny & Feid', 'Zach Bryan Featuring The War And Treaty', 'Taylor Swift', 'Oliver Anthony Music', 'Travis Scott Featuring Drake', 'Cardi B & Megan Thee Stallion', 'Drake Featuring SZA', 'Maluma & Carin Leon', 'Calle 24 x Chino Pacas x Fuerza Regida', 'The Beatles', 'Selena Gomez', 'Parker McCollum', 'Myke Towers', 'Taylor Swift', 'Olivia Rodrigo', 'Rod Wave Featuring 21 Savage', 'Sexyy Red', 'Jung Kook & Jack Harlow', 'Taylor Swift', 'Taylor Swift', 'Grupo Frontera & Grupo Firme', 'Dan + Shay', 'Dustin Lynch', 'Stray Kids', 'Jung Kook Featuring Latto', 'Taylor Swift', 'Taylor Swift', 'Carly Pearce Featuring Chris Stapleton', 'Lil Durk', 'Karol G', 'Riley Green Featuring Luke Combs', 'Luke Bryan', 'YoungBoy Never Broke Again & Rod Wave', '310babii']\n"
     ]
    }
   ],
   "source": [
    "print(len(artist),artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "501ff4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting week rank\n",
    "weekranktag=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"][1]/span')\n",
    "for i in weekranktag:\n",
    "    week_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e27ac1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '-', '2', '4', '3', '6', '8', '11', '10', '9', '-', '29', '15', '20', '18', '14', '-', '13', '22', '16', '17', '25', '27', '19', '24', '21', '28', '30', '23', '33', '37', '-', '12', '35', '34', '38', '-', '-', '43', '44', '36', '40', '42', '-', '39', '46', '48', '51', '31', '5', '55', '53', '26', '41', '62', '60', '67', '54', '69', '86', '52', '61', '32', '74', '66', '94', '57', '76', '45', '71', '75', '64', '70', '79', '78', '7', '63', '80', '82', '47', '56', '90', '84', '58', '73', '72', '88', '95', '81', '-', '49', '50', '59', '99', '-', '91', '-', '98', '-', '-']\n"
     ]
    }
   ],
   "source": [
    "print(len(week_rank),week_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4a07e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting week \n",
    "weektag=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"][2]/span')\n",
    "for i in weektag:\n",
    "    weeks.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a842551c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['28', '1', '15', '49', '3', '12', '34', '9', '42', '37', '1', '17', '33', '8', '7', '6', '59', '22', '22', '25', '20', '12', '9', '5', '6', '6', '18', '14', '44', '8', '7', '32', '3', '22', '28', '49', '1', '50', '14', '2', '31', '16', '6', '33', '21', '10', '3', '9', '3', '2', '8', '9', '3', '14', '9', '10', '7', '6', '38', '10', '18', '6', '2', '22', '14', '4', '5', '12', '3', '14', '16', '10', '9', '7', '7', '2', '12', '4', '19', '3', '2', '9', '11', '7', '3', '4', '12', '3', '6', '1', '15', '3', '3', '2', '1', '13', '1', '5', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "print(len(weeks),weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d24bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting peak week\n",
    "ptag=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"][2]/span')\n",
    "for i in ptag:\n",
    "    peek_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "554ed71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '2', '1', '2', '1', '1', '2', '8', '1', '7', '11', '12', '13', '14', '15', '11', '1', '4', '19', '6', '1', '8', '23', '5', '1', '2', '14', '25', '1', '26', '31', '4', '2', '25', '29', '1', '37', '3', '39', '40', '33', '11', '42', '4', '7', '46', '47', '48', '3', '5', '51', '52', '5', '7', '30', '11', '57', '3', '14', '60', '1', '55', '32', '55', '28', '44', '20', '14', '9', '1', '3', '14', '1', '68', '61', '7', '19', '77', '43', '7', '56', '24', '62', '5', '16', '19', '68', '84', '81', '90', '1', '10', '12', '94', '95', '22', '97', '92', '99', '100']\n"
     ]
    }
   ],
   "source": [
    "print(len(peek_rank),peek_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adefeb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is It Over Now? (Taylor's Version) [From The V...</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mi Ex Tenia Razon</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>91</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Different 'Round Here</td>\n",
       "      <td>Riley Green Featuring Luke Combs</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>But I Got A Beer In My Hand</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Better Than Ever</td>\n",
       "      <td>YoungBoy Never Broke Again &amp; Rod Wave</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Soak City (Do It)</td>\n",
       "      <td>310babii</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Song name  \\\n",
       "0                                        Cruel Summer   \n",
       "1                                         Lovin On Me   \n",
       "2                                  Paint The Town Red   \n",
       "3                                              Snooze   \n",
       "4   Is It Over Now? (Taylor's Version) [From The V...   \n",
       "..                                                ...   \n",
       "95                                  Mi Ex Tenia Razon   \n",
       "96                              Different 'Round Here   \n",
       "97                        But I Got A Beer In My Hand   \n",
       "98                                   Better Than Ever   \n",
       "99                                  Soak City (Do It)   \n",
       "\n",
       "                              Artist name Last week rank Peak rank  \\\n",
       "0                            Taylor Swift              1         1   \n",
       "1                             Jack Harlow              -         2   \n",
       "2                                Doja Cat              2         1   \n",
       "3                                     SZA              4         2   \n",
       "4                            Taylor Swift              3         1   \n",
       "..                                    ...            ...       ...   \n",
       "95                                Karol G             91        22   \n",
       "96       Riley Green Featuring Luke Combs              -        97   \n",
       "97                             Luke Bryan             98        92   \n",
       "98  YoungBoy Never Broke Again & Rod Wave              -        99   \n",
       "99                               310babii              -       100   \n",
       "\n",
       "   Weeks on board  \n",
       "0              28  \n",
       "1               1  \n",
       "2              15  \n",
       "3              49  \n",
       "4               3  \n",
       "..            ...  \n",
       "95             13  \n",
       "96              1  \n",
       "97              5  \n",
       "98              1  \n",
       "99              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##making dataframe\n",
    "df5=pd.DataFrame({'Song name':song , 'Artist name':artist,'Last week rank':week_rank,'Peak rank':peek_rank,'Weeks on board':weeks})\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccb2a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b7961b",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels. \n",
    "A) Book name \n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher \n",
    "E) Genre \n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64cdec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa685382",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d2bafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()     ##maximizing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8aeea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating empty list to store data\n",
    "book=[]\n",
    "author=[]\n",
    "sold=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03f5836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###extracting book name\n",
    "bt=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[2]')\n",
    "for i in bt:\n",
    "    book.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8523b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Da Vinci Code,The', 'Harry Potter and the Deathly Hallows', \"Harry Potter and the Philosopher's Stone\", 'Harry Potter and the Order of the Phoenix', 'Fifty Shades of Grey', 'Harry Potter and the Goblet of Fire', 'Harry Potter and the Chamber of Secrets', 'Harry Potter and the Prisoner of Azkaban', 'Angels and Demons', \"Harry Potter and the Half-blood Prince:Children's Edition\", 'Fifty Shades Darker', 'Twilight', 'Girl with the Dragon Tattoo,The:Millennium Trilogy', 'Fifty Shades Freed', 'Lost Symbol,The', 'New Moon', 'Deception Point', 'Eclipse', 'Lovely Bones,The', 'Curious Incident of the Dog in the Night-time,The', 'Digital Fortress', 'Short History of Nearly Everything,A', 'Girl Who Played with Fire,The:Millennium Trilogy', 'Breaking Dawn', 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar', 'Gruffalo,The', \"Jamie's 30-Minute Meals\", 'Kite Runner,The', 'One Day', 'Thousand Splendid Suns,A', \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\", \"Time Traveler's Wife,The\", 'Atonement', \"Bridget Jones's Diary:A Novel\", 'World According to Clarkson,The', \"Captain Corelli's Mandolin\", 'Sound of Laughter,The', 'Life of Pi', 'Billy Connolly', 'Child Called It,A', \"Gruffalo's Child,The\", \"Angela's Ashes:A Memoir of a Childhood\", 'Birdsong', 'Northern Lights:His Dark Materials S.', 'Labyrinth', 'Harry Potter and the Half-blood Prince', 'Help,The', 'Man and Boy', 'Memoirs of a Geisha', \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\", 'Island,The', 'PS, I Love You', 'You are What You Eat:The Plan That Will Change Your Life', 'Shadow of the Wind,The', 'Tales of Beedle the Bard,The', 'Broker,The', \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\", 'Subtle Knife,The:His Dark Materials S.', 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation', \"Delia's How to Cook:(Bk.1)\", 'Chocolat', 'Boy in the Striped Pyjamas,The', \"My Sister's Keeper\", 'Amber Spyglass,The:His Dark Materials S.', 'To Kill a Mockingbird', 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin', 'Dear Fatty', 'Short History of Tractors in Ukrainian,A', 'Hannibal', 'Lord of the Rings,The', 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio', 'Interpretation of Murder,The', 'Sharon Osbourne Extreme:My Autobiography', 'Alchemist,The:A Fable About Following Your Dream', \"At My Mother's Knee ...:and Other Low Joints\", 'Notes from a Small Island', 'Return of the Naked Chef,The', 'Bridget Jones: The Edge of Reason', \"Jamie's Italy\", 'I Can Make You Thin', 'Down Under', 'Summons,The', 'Small Island', 'Nigella Express', 'Brick Lane', \"Memory Keeper's Daughter,The\", 'Room on the Broom', 'About a Boy', 'My Booky Wook', 'God Delusion,The', '\"Beano\" Annual,The', 'White Teeth', 'House at Riverton,The', 'Book Thief,The', 'Nights of Rain and Stars', 'Ghost,The', 'Happy Days with the Naked Chef', 'Hunger Games,The:Hunger Games Trilogy', \"Lost Boy,The:A Foster Child's Search for the Love of a Family\", \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]\n"
     ]
    }
   ],
   "source": [
    "print(len(book),book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "552ec4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###extracting author name\n",
    "at=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[3]')\n",
    "for i in at:\n",
    "    author.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9249eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Brown, Dan', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'James, E. L.', 'Rowling, J.K.', 'Rowling, J.K.', 'Rowling, J.K.', 'Brown, Dan', 'Rowling, J.K.', 'James, E. L.', 'Meyer, Stephenie', 'Larsson, Stieg', 'James, E. L.', 'Brown, Dan', 'Meyer, Stephenie', 'Brown, Dan', 'Meyer, Stephenie', 'Sebold, Alice', 'Haddon, Mark', 'Brown, Dan', 'Bryson, Bill', 'Larsson, Stieg', 'Meyer, Stephenie', 'Carle, Eric', 'Donaldson, Julia', 'Oliver, Jamie', 'Hosseini, Khaled', 'Nicholls, David', 'Hosseini, Khaled', 'Larsson, Stieg', 'Niffenegger, Audrey', 'McEwan, Ian', 'Fielding, Helen', 'Clarkson, Jeremy', 'Bernieres, Louis de', 'Kay, Peter', 'Martel, Yann', 'Stephenson, Pamela', 'Pelzer, Dave', 'Donaldson, Julia', 'McCourt, Frank', 'Faulks, Sebastian', 'Pullman, Philip', 'Mosse, Kate', 'Rowling, J.K.', 'Stockett, Kathryn', 'Parsons, Tony', 'Golden, Arthur', 'McCall Smith, Alexander', 'Hislop, Victoria', 'Ahern, Cecelia', 'McKeith, Gillian', 'Zafon, Carlos Ruiz', 'Rowling, J.K.', 'Grisham, John', 'Atkins, Robert C.', 'Pullman, Philip', 'Truss, Lynne', 'Smith, Delia', 'Harris, Joanne', 'Boyne, John', 'Picoult, Jodi', 'Pullman, Philip', 'Lee, Harper', 'Gray, John', 'French, Dawn', 'Lewycka, Marina', 'Harris, Thomas', 'Tolkien, J. R. R.', 'Moore, Michael', 'Rubenfeld, Jed', 'Osbourne, Sharon', 'Coelho, Paulo', \"O'Grady, Paul\", 'Bryson, Bill', 'Oliver, Jamie', 'Fielding, Helen', 'Oliver, Jamie', 'McKenna, Paul', 'Bryson, Bill', 'Grisham, John', 'Levy, Andrea', 'Lawson, Nigella', 'Ali, Monica', 'Edwards, Kim', 'Donaldson, Julia', 'Hornby, Nick', 'Brand, Russell', 'Dawkins, Richard', '0', 'Smith, Zadie', 'Morton, Kate', 'Zusak, Markus', 'Binchy, Maeve', 'Harris, Robert', 'Oliver, Jamie', 'Collins, Suzanne', 'Pelzer, Dave', 'Oliver, Jamie']\n"
     ]
    }
   ],
   "source": [
    "print(len(author),author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d3bbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###extracting book sold\n",
    "st=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[4]')\n",
    "for i in st:\n",
    "    sold.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "942d259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['5,094,805', '4,475,152', '4,200,654', '4,179,479', '3,758,936', '3,583,215', '3,484,047', '3,377,906', '3,193,946', '2,950,264', '2,479,784', '2,315,405', '2,233,570', '2,193,928', '2,183,031', '2,152,737', '2,062,145', '2,052,876', '2,005,598', '1,979,552', '1,928,900', '1,852,919', '1,814,784', '1,787,118', '1,783,535', '1,781,269', '1,743,266', '1,629,119', '1,616,068', '1,583,992', '1,555,135', '1,546,886', '1,539,428', '1,508,205', '1,489,403', '1,352,318', '1,310,207', '1,310,176', '1,231,957', '1,217,712', '1,208,711', '1,204,058', '1,184,967', '1,181,503', '1,181,093', '1,153,181', '1,132,336', '1,130,802', '1,126,337', '1,115,549', '1,108,328', '1,107,379', '1,104,403', '1,092,349', '1,090,847', '1,087,262', '1,054,196', '1,037,160', '1,023,688', '1,015,956', '1,009,873', '1,004,414', '1,003,780', '1,002,314', '998,213', '992,846', '986,753', '986,115', '970,509', '967,466', '963,353', '962,515', '959,496', '956,114', '945,640', '931,312', '925,425', '924,695', '906,968', '905,086', '890,847', '869,671', '869,659', '862,602', '856,540', '845,858', '842,535', '828,215', '820,563', '816,907', '816,585', '815,586', '814,370', '809,641', '808,900', '807,311', '794,201', '792,187', '791,507', '791,095']\n"
     ]
    }
   ],
   "source": [
    "print(len(sold),sold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89d0880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###extracting publisher\n",
    "pt=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[5]')\n",
    "for i in pt:\n",
    "    publisher.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f56929fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Transworld', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Random House', 'Bloomsbury', 'Bloomsbury', 'Bloomsbury', 'Transworld', 'Bloomsbury', 'Random House', 'Little, Brown Book', 'Quercus', 'Random House', 'Transworld', 'Little, Brown Book', 'Transworld', 'Little, Brown Book', 'Pan Macmillan', 'Random House', 'Transworld', 'Transworld', 'Quercus', 'Little, Brown Book', 'Penguin', 'Pan Macmillan', 'Penguin', 'Bloomsbury', 'Hodder & Stoughton', 'Bloomsbury', 'Quercus', 'Random House', 'Random House', 'Pan Macmillan', 'Penguin', 'Random House', 'Random House', 'Canongate', 'HarperCollins', 'Orion', 'Pan Macmillan', 'HarperCollins', 'Random House', 'Scholastic Ltd.', 'Orion', 'Bloomsbury', 'Penguin', 'HarperCollins', 'Random House', 'Little, Brown Book', 'Headline', 'HarperCollins', 'Penguin', 'Orion', 'Bloomsbury', 'Random House', 'Random House', 'Scholastic Ltd.', 'Profile Books Group', 'Random House', 'Transworld', 'Random House Childrens Books G', 'Hodder & Stoughton', 'Scholastic Ltd.', 'Random House', 'HarperCollins', 'Random House', 'Penguin', 'Random House', 'HarperCollins', 'Penguin', 'Headline', 'Little, Brown Book', 'HarperCollins', 'Transworld', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Transworld', 'Transworld', 'Random House', 'Headline', 'Random House', 'Transworld', 'Penguin', 'Pan Macmillan', 'Penguin', 'Hodder & Stoughton', 'Transworld', 'D.C. Thomson', 'Penguin', 'Pan Macmillan', 'Transworld', 'Orion', 'Random House', 'Penguin', 'Scholastic Ltd.', 'Orion', 'Penguin']\n"
     ]
    }
   ],
   "source": [
    "print(len(publisher),publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5d9800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###extracting genre\n",
    "gt=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[6]')\n",
    "for i in gt:\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "804aa4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Crime, Thriller & Adventure', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Romance & Sagas', \"Children's Fiction\", \"Children's Fiction\", \"Children's Fiction\", 'Crime, Thriller & Adventure', \"Children's Fiction\", 'Romance & Sagas', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Romance & Sagas', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Popular Science', 'Crime, Thriller & Adventure', 'Young Adult Fiction', 'Picture Books', 'Picture Books', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Humour: Collections & General', 'General & Literary Fiction', 'Autobiography: General', 'General & Literary Fiction', 'Biography: The Arts', 'Autobiography: General', 'Picture Books', 'Autobiography: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Science Fiction & Fantasy', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'General & Literary Fiction', 'Fitness & Diet', 'General & Literary Fiction', \"Children's Fiction\", 'Crime, Thriller & Adventure', 'Fitness & Diet', 'Young Adult Fiction', 'Usage & Writing Guides', 'Food & Drink: General', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Young Adult Fiction', 'General & Literary Fiction', 'Popular Culture & Media: General Interest', 'Autobiography: The Arts', 'General & Literary Fiction', 'Crime, Thriller & Adventure', 'Science Fiction & Fantasy', 'Current Affairs & Issues', 'Crime, Thriller & Adventure', 'Autobiography: The Arts', 'General & Literary Fiction', 'Autobiography: The Arts', 'Travel Writing', 'Food & Drink: General', 'General & Literary Fiction', 'National & Regional Cuisine', 'Fitness & Diet', 'Travel Writing', 'Crime, Thriller & Adventure', 'General & Literary Fiction', 'Food & Drink: General', 'General & Literary Fiction', 'General & Literary Fiction', 'Picture Books', 'General & Literary Fiction', 'Autobiography: The Arts', 'Popular Science', \"Children's Annuals\", 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'General & Literary Fiction', 'Food & Drink: General', 'Young Adult Fiction', 'Biography: General', 'Food & Drink: General']\n"
     ]
    }
   ],
   "source": [
    "print(len(genre),genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "897b573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##making dataframe\n",
    "df6=pd.DataFrame({'Book name':book, 'Author name':author,'Volumes sold':sold ,'Publisher':publisher, 'Genre':genre})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752fd05",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "to find the following details: \n",
    "A) Name \n",
    "B) Year span \n",
    "C) Genre \n",
    "D) Run time \n",
    "E) Ratings \n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5daaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e56253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5618e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window() ##maximizing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63514064",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating emptylist to store data\n",
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "rating=[]\n",
    "votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b31c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extracting name\n",
    "nt=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/a')\n",
    "for i in nt:\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4feed479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Game of Thrones', 'Stranger Things', 'The Walking Dead', '13 Reasons Why', 'The 100', 'Orange Is the New Black', 'Riverdale', \"Grey's Anatomy\", 'The Flash', 'Arrow', 'Money Heist', 'The Big Bang Theory', 'Black Mirror', 'Sherlock', 'Vikings', 'Pretty Little Liars', 'The Vampire Diaries', 'American Horror Story', 'Breaking Bad', 'Lucifer', 'Supernatural', 'Prison Break', 'How to Get Away with Murder', 'Teen Wolf', 'The Simpsons', 'Once Upon a Time', 'Narcos', 'Daredevil', 'Friends', 'How I Met Your Mother', 'Suits', 'Mr. Robot', 'The Originals', 'Supergirl', 'Gossip Girl', 'Sense8', 'Gotham', 'Westworld', 'Jessica Jones', 'Modern Family', 'Rick and Morty', 'Shadowhunters', 'The End of the F***ing World', 'House of Cards', 'Dark', 'Elite', 'Sex Education', 'Shameless', 'New Girl', 'Agents of S.H.I.E.L.D.', 'You', 'Dexter', 'Fear the Walking Dead', 'Family Guy', 'The Blacklist', 'Lost', 'Peaky Blinders', 'House', 'Quantico', 'Orphan Black', 'Homeland', 'Blindspot', \"DC's Legends of Tomorrow\", \"The Handmaid's Tale\", 'Chilling Adventures of Sabrina', 'The Good Doctor', 'Jane the Virgin', 'Glee', 'South Park', 'Brooklyn Nine-Nine', 'Under the Dome', 'The Umbrella Academy', 'True Detective', 'The OA', 'Desperate Housewives', 'Better Call Saul', 'Bates Motel', 'The Punisher', 'Atypical', 'Dynasty', 'This Is Us', 'The Good Place', 'Iron Fist', 'The Rain', 'Mindhunter', 'Revenge', 'Luke Cage', 'Scandal', 'The Defenders', 'Big Little Lies', 'Insatiable', 'The Mentalist', 'The Crown', 'Chernobyl', 'iZombie', 'Reign', 'A Series of Unfortunate Events', 'Criminal Minds', 'Scream: The TV Series', 'The Haunting of Hill House']\n"
     ]
    }
   ],
   "source": [
    "print(len(name),name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c44e255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extractingyear span\n",
    "yt=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/span[2]')\n",
    "for i in yt:\n",
    "    year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21f0b61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['(2011–2019)', '(2016–2025)', '(2010–2022)', '(2017–2020)', '(2014–2020)', '(2013–2019)', '(2017–2023)', '(2005– )', '(2014–2023)', '(2012–2020)', '(2017–2021)', '(2007–2019)', '(2011– )', '(2010– )', '(2013–2020)', '(2010–2017)', '(2009–2017)', '(2011– )', '(2008–2013)', '(2016–2021)', '(2005–2020)', '(2005–2017)', '(2014–2020)', '(2011–2017)', '(1989– )', '(2011–2018)', '(I) (2015–2017)', '(2015–2018)', '(1994–2004)', '(2005–2014)', '(2011–2019)', '(2015–2019)', '(2013–2018)', '(2015–2021)', '(2007–2012)', '(2015–2018)', '(2014–2019)', '(2016–2022)', '(2015–2019)', '(2009–2020)', '(2013– )', '(2016–2019)', '(2017–2019)', '(2013–2018)', '(2017–2020)', '(2018–2024)', '(2019–2023)', '(2011–2021)', '(2011–2018)', '(2013–2020)', '(2018–2024)', '(2006–2013)', '(2015–2023)', '(1999– )', '(2013–2023)', '(2004–2010)', '(2013–2022)', '(2004–2012)', '(2015–2018)', '(2013–2017)', '(2011–2020)', '(2015–2020)', '(2016–2022)', '(2017– )', '(2018–2020)', '(2017– )', '(2014–2019)', '(2009–2015)', '(1997– )', '(2013–2021)', '(2013–2015)', '(2019–2024)', '(2014– )', '(2016–2019)', '(2004–2012)', '(2015–2022)', '(2013–2017)', '(2017–2019)', '(2017–2021)', '(2017–2022)', '(2016–2022)', '(2016–2020)', '(2017–2018)', '(2018–2020)', '(2017–2019)', '(2011–2015)', '(2016–2018)', '(2012–2018)', '(2017)', '(2017–2019)', '(2018–2019)', '(2008–2015)', '(2016–2023)', '(2019)', '(2015–2019)', '(2013–2017)', '(2017–2019)', '(2005– )', '(2015–2019)', '(2018)']\n"
     ]
    }
   ],
   "source": [
    "print(len(year),year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c38a4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extracting runtime\n",
    "time=[]\n",
    "tt=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[1]/span[3]')\n",
    "for i in tt:\n",
    "    time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e1ff13a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['4,189 min', '51 min', '44 min', '60 min', '43 min', '59 min', '45 min', '41 min', '43 min', '42 min', '70 min', '5,702 min', '60 min', '88 min', '44 min', '44 min', '43 min', '60 min', '3,030 min', '42 min', '44 min', '44 min', '43 min', '41 min', '22 min', '60 min', '49 min', '54 min', '5,280 min', '4,576 min', '44 min', '49 min', '45 min', '43 min', '42 min', '60 min', '42 min', '62 min', '56 min', '22 min', '23 min', '42 min', '25 min', '3,804 min', '1,455 min', '60 min', '45 min', '46 min', '22 min', '45 min', '45 min', '5,076 min', '44 min', '22 min', '43 min', '44 min', '2,109 min', '7,788 min', '42 min', '44 min', '55 min', '42 min', '42 min', '60 min', '60 min', '41 min', '60 min', '44 min', '22 min', '22 min', '43 min', '60 min', '55 min', '60 min', '45 min', '3,154 min', '45 min', '53 min', '30 min', '42 min', '45 min', '22 min', '55 min', '45 min', '60 min', '44 min', '55 min', '43 min', '50 min', '356 min', '45 min', '43 min', '58 min', '330 min', '42 min', '42 min', '50 min', '42 min', '45 min', '572 min']\n"
     ]
    }
   ],
   "source": [
    "print(len(time),time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2496187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extracting genre\n",
    "gt=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[1]/span[5]')\n",
    "for i in gt:\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "722a97f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Drama', 'Comedy, Romance', 'Drama, Mystery, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Sci-Fi', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Drama, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama', 'Comedy, Drama', 'Comedy, Romance', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Crime, Drama, Mystery', 'Drama, Horror, Sci-Fi', 'Animation, Comedy', 'Crime, Drama, Mystery', 'Adventure, Drama, Fantasy', 'Crime, Drama', 'Drama, Mystery', 'Crime, Drama, Mystery', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Action, Crime, Drama', 'Action, Adventure, Drama', 'Drama, Sci-Fi, Thriller', 'Drama, Fantasy, Horror', 'Drama', 'Comedy', 'Comedy, Drama, Music', 'Animation, Comedy', 'Comedy, Crime', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Drama, Fantasy, Mystery', 'Comedy, Drama, Mystery', 'Crime, Drama', 'Drama, Horror, Mystery', 'Action, Crime, Drama', 'Comedy, Drama', 'Drama', 'Comedy, Drama, Romance', 'Comedy, Drama, Fantasy', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Drama, Mystery, Thriller', 'Action, Crime, Drama', 'Drama, Thriller', 'Action, Adventure, Crime', 'Crime, Drama, Mystery', 'Comedy, Drama, Thriller', 'Crime, Drama, Mystery', 'Biography, Drama, History', 'Drama, History, Thriller', 'Comedy, Crime, Drama', 'Drama', 'Adventure, Comedy, Drama', 'Crime, Drama, Mystery', 'Comedy, Crime, Drama', 'Drama, Horror, Mystery']\n"
     ]
    }
   ],
   "source": [
    "print(len(genre),genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "805ba4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extracting rating\n",
    "rt=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/div[1]/div[1]')\n",
    "for i in rt:\n",
    "    rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9e1a477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['9.2', '8.7', '8.1', '7.5', '7.6', '8', '6.5', '7.6', '7.5', '7.5', '8.2', '8.2', '8.7', '9.1', '8.5', '7.4', '7.7', '8', '9.5', '8.1', '8.4', '8.3', '8.1', '7.7', '8.7', '7.7', '8.8', '8.6', '8.9', '8.3', '8.4', '8.5', '8.3', '6.2', '7.5', '8.2', '7.8', '8.5', '7.9', '8.5', '9.1', '6.5', '8', '8.7', '8.7', '7.2', '8.3', '8.5', '7.8', '7.5', '7.7', '8.7', '6.8', '8.2', '8', '8.3', '8.8', '8.7', '6.7', '8.3', '8.3', '7.3', '6.8', '8.4', '7.4', '8', '7.9', '6.8', '8.7', '8.4', '6.5', '7.9', '8.9', '7.8', '7.6', '9', '8.1', '8.5', '8.2', '7.3', '8.7', '8.2', '6.4', '6.3', '8.6', '7.8', '7.3', '7.7', '7.2', '8.4', '6.5', '8.2', '8.6', '9.3', '7.8', '7.5', '7.8', '8.1', '7', '8.6']\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "53c0c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extracting votesv\n",
    "vt=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "for i in vt:\n",
    "    votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c42c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['2,225,424', '1,292,564', '1,055,722', '309,990', '269,108', '315,896', '152,807', '332,390', '364,559', '442,533', '514,084', '847,972', '619,451', '974,740', '566,726', '175,688', '341,999', '337,411', '2,065,697', '346,704', '471,705', '567,305', '162,901', '160,011', '428,292', '233,889', '457,002', '464,612', '1,058,953', '715,955', '458,989', '409,228', '144,730', '128,305', '188,134', '160,659', '238,189', '524,070', '223,511', '467,082', '578,670', '68,756', '212,649', '523,515', '427,002', '88,482', '336,583', '269,839', '240,312', '223,769', '287,959', '751,417', '140,299', '357,906', '273,665', '582,320', '617,901', '494,973', '63,215', '115,501', '355,799', '77,853', '108,982', '252,377', '105,546', '108,851', '57,080', '153,897', '398,343', '347,084', '110,946', '267,139', '615,622', '112,105', '136,739', '617,081', '114,900', '257,288', '100,467', '24,411', '153,743', '181,671', '137,469', '40,506', '321,282', '123,691', '137,531', '78,553', '114,317', '218,021', '31,694', '196,106', '238,973', '831,789', '72,948', '53,246', '65,339', '213,068', '44,364', '277,668']\n"
     ]
    }
   ],
   "source": [
    "print(len(votes),votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05088701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>4,189 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,225,424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,292,564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,055,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>309,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>269,108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>53,246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>213,068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>277,668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "     Run time Ratings      Votes  \n",
       "0   4,189 min     9.2  2,225,424  \n",
       "1      51 min     8.7  1,292,564  \n",
       "2      44 min     8.1  1,055,722  \n",
       "3      60 min     7.5    309,990  \n",
       "4      43 min     7.6    269,108  \n",
       "..        ...     ...        ...  \n",
       "95     42 min     7.5     53,246  \n",
       "96     50 min     7.8     65,339  \n",
       "97     42 min     8.1    213,068  \n",
       "98     45 min       7     44,364  \n",
       "99    572 min     8.6    277,668  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###making dataframe\n",
    "df7=pd.DataFrame({'Name':name, 'Year span' :year, 'Genre':genre ,'Run time' :time, 'Ratings':rating , 'Votes':votes})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930a22e",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/ You \n",
    "have to find the following details: \n",
    "A) Dataset name \n",
    "B) Data type \n",
    "C) Task \n",
    "D) Attribute type \n",
    "E) No of instances \n",
    "F) No of attribute G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37df9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gettig driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a13d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ddff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window() ##maximizing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6d28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on datasets\n",
    "dataset=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c946957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store data\n",
    "name=[] \n",
    "datatype=[]\n",
    "task=[]\n",
    "atype=[]\n",
    "noi=[]\n",
    "attribute=[] \n",
    "year=[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8dd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3extracting url\n",
    "urltag=driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]/a')\n",
    "for i in urltag:\n",
    "    url.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcf191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['https://archive.ics.uci.edu/dataset/53/iris', 'https://archive.ics.uci.edu/dataset/45/heart+disease', 'https://archive.ics.uci.edu/dataset/2/adult', 'https://archive.ics.uci.edu/dataset/109/wine', 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'https://archive.ics.uci.edu/dataset/34/diabetes', 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset', 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'https://archive.ics.uci.edu/dataset/186/wine+quality', 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik']\n"
     ]
    }
   ],
   "source": [
    "print(len(url),url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00eef47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting name of dataset\n",
    "nt=driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]/a')\n",
    "for i in nt:\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b92c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Iris', 'Heart Disease', 'Adult', 'Wine', 'Breast Cancer Wisconsin (Diagnostic)', 'Diabetes', 'Dry Bean Dataset', 'Car Evaluation', 'Wine Quality', 'Rice (Cammeo and Osmancik)']\n"
     ]
    }
   ],
   "source": [
    "print(len(name),name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a03788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting datatype\n",
    "typetag=driver.find_elements(By.XPATH,'//div[@class=\"col-span-3 flex items-center gap-2\"][2]/span')\n",
    "for i in typetag:\n",
    "    datatype.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd0c0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Tabular', 'Multivariate', 'Multivariate', 'Tabular', 'Multivariate', 'Multivariate, Time-Series', 'Multivariate', 'Multivariate', 'Multivariate', 'Multivariate']\n"
     ]
    }
   ],
   "source": [
    "print(len(datatype),datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72959122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting no of instances\n",
    "noit=driver.find_elements(By.XPATH,'//div[@class=\"col-span-3 flex items-center gap-2\"][3]/span')\n",
    "for i in noit:\n",
    "    noi.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f5b4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['150 Instances', '303 Instances', '48.84K Instances', '178 Instances', '569 Instances', '1 Instances', '13.61K Instances', '1.73K Instances', '4.9K Instances', '3.81K Instances']\n"
     ]
    }
   ],
   "source": [
    "print(len(noi),noi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45d3415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting no of attributes\n",
    "noat=driver.find_elements(By.XPATH,'//div[@class=\"col-span-3 flex items-center gap-2\"][4]/span')\n",
    "for i in noat:\n",
    "    attribute.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53f7bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['4 Features', '13 Features', '14 Features', '13 Features', '30 Features', '20 Features', '16 Features', '6 Features', '12 Features', '7 Features']\n"
     ]
    }
   ],
   "source": [
    "print(len(attribute),attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca5c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clicking on expand all filter to extract data\n",
    "expandall=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')\n",
    "expandall.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0810f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting attribute type\n",
    "\n",
    "att=driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[2]')\n",
    "for i in att:\n",
    "    atype.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ba7afff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Real', 'Categorical, Integer, Real', 'Categorical, Integer', 'Integer, Real', 'Real', 'Categorical, Integer', 'Integer, Real', 'Categorical', 'Real', 'Real']\n"
     ]
    }
   ],
   "source": [
    "print(len(atype),atype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a42a83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extractig year \n",
    "yt=driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[3]')\n",
    "for i in yt:\n",
    "    year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53f330ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['7/1/1988', '7/1/1988', '5/1/1996', '7/1/1991', '11/1/1995', 'N/A', '9/14/2020', '6/1/1997', '10/7/2009', '10/6/2019']\n"
     ]
    }
   ],
   "source": [
    "print(len(year),year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95131a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##extracting task\n",
    "tasktag=driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/p')\n",
    "for i in tasktag:\n",
    "    task.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1d2ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.', '4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach', 'Predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset.', 'Using chemical analysis to determine the origin of wines', 'Diagnostic Wisconsin Breast Cancer Database.', \"This diabetes dataset is from AIM '94\", 'Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.', 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests (see [Cortez et al., 2009], http://www3.dsi.uminho.pt/pcortez/wine/).', \"A total of 3810 rice grain's images were taken for the two species, processed and feature inferences were made. 7 morphological features were obtained for each grain of rice.\"]\n"
     ]
    }
   ],
   "source": [
    "print(len(task),task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc0282f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Using chemical analysis to determine the origi...</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>This diabetes dataset is from AIM '94</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Derived from simple hierarchical decision mode...</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Two datasets are included, related to red and ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>A total of 3810 rice grain's images were taken...</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset name                  Data type  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                         Heart Disease               Multivariate   \n",
       "2                                 Adult               Multivariate   \n",
       "3                                  Wine                    Tabular   \n",
       "4  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "5                              Diabetes  Multivariate, Time-Series   \n",
       "6                      Dry Bean Dataset               Multivariate   \n",
       "7                        Car Evaluation               Multivariate   \n",
       "8                          Wine Quality               Multivariate   \n",
       "9            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "\n",
       "                                                Task  \\\n",
       "0  A small classic dataset from Fisher, 1936. One...   \n",
       "1  4 databases: Cleveland, Hungary, Switzerland, ...   \n",
       "2  Predict whether income exceeds $50K/yr based o...   \n",
       "3  Using chemical analysis to determine the origi...   \n",
       "4       Diagnostic Wisconsin Breast Cancer Database.   \n",
       "5              This diabetes dataset is from AIM '94   \n",
       "6  Images of 13,611 grains of 7 different registe...   \n",
       "7  Derived from simple hierarchical decision mode...   \n",
       "8  Two datasets are included, related to red and ...   \n",
       "9  A total of 3810 rice grain's images were taken...   \n",
       "\n",
       "               Attribute type   No of instances No of attribute       Year  \n",
       "0                        Real     150 Instances      4 Features   7/1/1988  \n",
       "1  Categorical, Integer, Real     303 Instances     13 Features   7/1/1988  \n",
       "2        Categorical, Integer  48.84K Instances     14 Features   5/1/1996  \n",
       "3               Integer, Real     178 Instances     13 Features   7/1/1991  \n",
       "4                        Real     569 Instances     30 Features  11/1/1995  \n",
       "5        Categorical, Integer       1 Instances     20 Features        N/A  \n",
       "6               Integer, Real  13.61K Instances     16 Features  9/14/2020  \n",
       "7                 Categorical   1.73K Instances      6 Features   6/1/1997  \n",
       "8                        Real    4.9K Instances     12 Features  10/7/2009  \n",
       "9                        Real   3.81K Instances      7 Features  10/6/2019  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "df8=pd.DataFrame({'Dataset name':name ,' Data type':datatype , 'Task':task , 'Attribute type':atype , 'No of instances':noi, 'No of attribute':attribute , 'Year':year})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07648e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228eeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
